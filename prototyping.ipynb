{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3469ffe-623d-48ca-bb8f-f81741c4e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from langdetect import detect, DetectorFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d39e36a2-0065-4bd9-a1e9-deacdeab1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DetectorFactory.seed = 0 #fix langdetect randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a248c0-69a4-413a-acc6-3eeb77cbbcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/arturschaefer/Documents/Freelancing/Repos/rag-llm-example/data/docs'),\n",
       " PosixPath('/Users/arturschaefer/Documents/Freelancing/Repos/rag-llm-example/index'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base paths\n",
    "BASE_DIR = Path().resolve()\n",
    "DOCS_DIR = BASE_DIR / \"data\" / \"docs\"\n",
    "INDEX_DIR = BASE_DIR / \"index\"\n",
    "\n",
    "DOCS_DIR, INDEX_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22ec9ae2-0f19-4729-9f74-4bfa06f0093a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " ['employee_handbook',\n",
       "  'it_security',\n",
       "  'remote_work_policy',\n",
       "  'travel_expenses',\n",
       "  'vacation_policy'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load markdown documents\n",
    "\n",
    "def load_documents(docs_dir: Path) -> List[Dict]:\n",
    "    documents = []\n",
    "    for path in sorted(docs_dir.glob(\"*.md\")):\n",
    "        text = path.read_text(encoding=\"utf-8\")\n",
    "        lines = text.splitlines()\n",
    "        \n",
    "        # use first Markdown heading as title\n",
    "        if lines and lines[0].lstrip().startswith(\"#\"):\n",
    "            title = lines[0].lstrip(\"#\").strip()\n",
    "        else:\n",
    "            title = path.stem\n",
    "        \n",
    "        documents.append({\n",
    "            \"id\": path.stem,\n",
    "            \"title\": title,\n",
    "            \"text\": text\n",
    "        })\n",
    "    return documents\n",
    "\n",
    "docs = load_documents(DOCS_DIR)\n",
    "len(docs), [d[\"id\"] for d in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518aafd4-8a74-4ed4-8930-457a5f2570d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunk documents (simple double-newline split)\n",
    "\n",
    "def chunk_document(doc: Dict, min_chars: int = 40) -> List[Dict]:\n",
    "    raw_chunks = [c.strip() for c in doc[\"text\"].split(\"\\n\\n\") if c.strip()]\n",
    "    chunks = []\n",
    "\n",
    "    for i, c in enumerate(raw_chunks):\n",
    "        if len(c) < min_chars:\n",
    "            continue\n",
    "        chunks.append({\n",
    "            \"chunk_id\": f\"{doc['id']}-{i}\",\n",
    "            \"doc_id\": doc[\"id\"],\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"text\": c,\n",
    "        })\n",
    "    return chunks\n",
    "\n",
    "all_chunks = []\n",
    "for d in docs:\n",
    "    all_chunks.extend(chunk_document(d))\n",
    "\n",
    "len(all_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eaae663-22a1-4c68-ae6e-87b44ca50618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings\n",
    "\n",
    "EMBED_MODEL = \"sentence-transformers/distiluse-base-multilingual-cased-v2\"\n",
    "embed_model = SentenceTransformer(EMBED_MODEL)\n",
    "\n",
    "texts = [c[\"text\"] for c in all_chunks]\n",
    "embeddings = embed_model.encode(texts, convert_to_numpy=True, normalize_embeddings=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c07f035-be26-4ba2-bfba-a1fe23ca18f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings\n",
    "\n",
    "np.save(INDEX_DIR / \"embeddings.npy\", embeddings)\n",
    "with open(INDEX_DIR / \"chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_chunks, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5675cddb-c95d-431e-8254-eab1edee4418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': 'vacation_policy-1',\n",
       "  'doc_id': 'vacation_policy',\n",
       "  'title': 'Vacation Policy',\n",
       "  'text': '**1. Annual Leave Entitlement**  \\nEmployees receive 25 days of paid vacation per year. Leave is accrued monthly during the first year.',\n",
       "  'score': 0.31855595111846924},\n",
       " {'chunk_id': 'vacation_policy-2',\n",
       "  'doc_id': 'vacation_policy',\n",
       "  'title': 'Vacation Policy',\n",
       "  'text': '**2. Request Procedure**  \\nVacation requests must be submitted via the HR portal at least two weeks in advance. Approval is subject to team workload and staffing requirements.',\n",
       "  'score': 0.259296715259552},\n",
       " {'chunk_id': 'remote_work_policy-1',\n",
       "  'doc_id': 'remote_work_policy',\n",
       "  'title': 'Remote Work Policy',\n",
       "  'text': '**1. Eligibility**  \\nEmployees may work remotely up to three days per week, subject to manager approval.',\n",
       "  'score': 0.2439272403717041}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever (semantic search)\n",
    "\n",
    "def retrieve(query: str, k: int = 5) -> List[Dict]:\n",
    "    q_emb = embed_model.encode([query], normalize_embeddings=True)[0]\n",
    "    sims = embeddings @ q_emb  # cosine similarity since normalized\n",
    "    top_idx = np.argsort(-sims)[:k]\n",
    "\n",
    "    results = []\n",
    "    for idx in top_idx:\n",
    "        c = all_chunks[idx]\n",
    "        results.append({\n",
    "            \"chunk_id\": c[\"chunk_id\"],\n",
    "            \"doc_id\": c[\"doc_id\"],\n",
    "            \"title\": c[\"title\"],\n",
    "            \"text\": c[\"text\"],\n",
    "            \"score\": float(sims[idx]),\n",
    "        })\n",
    "    return results\n",
    "\n",
    "retrieve(\"Wie viele Urlaubstage habe ich?\", k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82c44468-c49c-420e-b847-602bcc9a95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language detection\n",
    "\n",
    "def detect_language(text: str) -> str:\n",
    "    cleaned = text.strip()\n",
    "    if not cleaned:\n",
    "        return \"en\"\n",
    "     \n",
    "    lang = detect(cleaned)\n",
    "    if lang in [\"de\", \"en\"]:\n",
    "        return lang\n",
    "    else: return \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a5fb513-3b41-4991-8f87-a67e4b52524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the rag prompt - optimized for flan-t5\n",
    "\n",
    "def build_prompt(query: str, contexts: List[Dict]) -> str:\n",
    "    user_lang = detect_language(query)\n",
    "\n",
    "    # keep context short â€“ flan-t5-base has limited context\n",
    "    context_parts = []\n",
    "    for c in contexts:\n",
    "        context_parts.append(c[\"text\"])\n",
    "    context_str = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    if user_lang == \"de\":\n",
    "        # Simplified instruction that works better with flan-t5\n",
    "        instruction = (\n",
    "            \"Answer the question based on the context below. Answer in full sentences. \"\n",
    "            \"Answer in German.\\n\\n\"\n",
    "        )\n",
    "        prompt = (\n",
    "            instruction +\n",
    "            \"Context:\\n\" + context_str + \"\\n\\n\" +\n",
    "            \"Frage: \" + query + \"\\n\" +\n",
    "            \"Antwort:\"\n",
    "        )\n",
    "    else:\n",
    "        instruction = (\n",
    "            \"Answer the question based on the context below. Answer in full sentences.\\n\\n\"\n",
    "        )\n",
    "        prompt = (\n",
    "            instruction +\n",
    "            \"Context:\\n\" + context_str + \"\\n\\n\" +\n",
    "            \"Question: \" + query + \"\\n\" +\n",
    "            \"Answer:\"\n",
    "        )\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63f749bc-b4f4-4bf0-935f-a870a55af13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# local llm using transformers\n",
    "\n",
    "LLM_NAME = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLM_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(LLM_NAME)\n",
    "\n",
    "llm_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",  # or \"cpu\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "577bef92-317a-4dd8-94c7-2002bec6ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm call helper - optimized parameters\n",
    "\n",
    "def call_local_llm(prompt: str, max_new_tokens: int = 128, temperature: float = 0.3) -> str:\n",
    "    result = llm_pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,  # Enable sampling for better multilingual output\n",
    "        temperature=temperature,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "    raw = result[0][\"generated_text\"]\n",
    "    return raw.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7a4b0fd-016c-4ef0-8a60-972478284aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: For better German performance, consider these alternatives:\n",
    "# - \"google/mt5-base\" (better multilingual support)\n",
    "# - \"google/flan-t5-large\" (better overall quality)\n",
    "# - Use API: OpenAI GPT-3.5/4, Anthropic Claude, etc.\n",
    "# flan-t5-base has limited multilingual capabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51768962-1c1d-46ac-9bce-c7378df64a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full rag pipeline - optimized retrieval\n",
    "\n",
    "def rag_answer(query: str, k: int = 3) -> Dict:\n",
    "    # Use fewer contexts (k=3 instead of 5) for better focus\n",
    "    contexts = retrieve(query, k=k)\n",
    "    prompt = build_prompt(query, contexts)\n",
    "    answer = call_local_llm(prompt, max_new_tokens=100)\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"sources\": contexts\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf97d0-d871-4ba2-999c-728af83de825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81c11e91-35c7-42dc-bbb4-8ea0fa625a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antwort:\n",
      "25\n",
      "\n",
      "\n",
      "Quellen:\n",
      "- Vacation Policy: **1. Annual Leave Entitlement**  \n",
      "Employees receive 25 days of paid vacation per year. Leave is accr... (score: 0.346)\n",
      "- Travel & Expense Guidelines: **3. Meals**  \n",
      "Per-diem allowances follow local regulations. Receipts must be uploaded within ten da... (score: 0.274)\n",
      "- Remote Work Policy: **1. Eligibility**  \n",
      "Employees may work remotely up to three days per week, subject to manager appro... (score: 0.265)\n"
     ]
    }
   ],
   "source": [
    "res = rag_answer(\"how many vacation days do I get?\", k=3)\n",
    "\n",
    "print(\"Antwort:\")\n",
    "print(res[\"answer\"])\n",
    "\n",
    "print(\"\\n\\nQuellen:\")\n",
    "for s in res[\"sources\"]:\n",
    "    print(f\"- {s['title']}: {s['text'][:100]}... (score: {s['score']:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a0d4f3-8ed5-45e7-a146-1fcc9ca252d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb2080-1686-46dc-a089-956f2b4d6986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698f81f-3669-4610-9f7b-f706063fddfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289fe2a-9128-4c9c-b0ed-3392c39e0244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
